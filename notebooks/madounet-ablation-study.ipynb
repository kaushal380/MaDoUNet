{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1574219,"sourceType":"datasetVersion","datasetId":930614},{"sourceId":6954765,"sourceType":"datasetVersion","datasetId":3994523},{"sourceId":7681479,"sourceType":"datasetVersion","datasetId":1316959}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"55d966e2","cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom torchmetrics.classification import (\n    BinaryJaccardIndex, BinaryF1Score, BinaryAccuracy,\n    BinaryRecall, BinaryPrecision, BinaryAUROC\n)\nfrom tqdm import tqdm\nimport timm\n\n# Detect device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:43:09.982109Z","iopub.execute_input":"2025-07-18T05:43:09.982435Z","iopub.status.idle":"2025-07-18T05:43:28.370172Z","shell.execute_reply.started":"2025-07-18T05:43:09.982407Z","shell.execute_reply":"2025-07-18T05:43:28.369516Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":1},{"id":"82f03986","cell_type":"code","source":"class UpBlock(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_ch, out_ch, 2, 2)\n        self.conv1 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n        self.act = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.up(x)\n        x = self.act(self.conv1(x))\n        x = self.act(self.conv2(x))\n        return x\n\nclass SkipUpBlock(nn.Module):\n    def __init__(self, in_ch, skip_ch, out_ch):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_ch, out_ch, 2, 2)\n        self.conv1 = nn.Conv2d(out_ch + skip_ch, out_ch, 3, padding=1)\n        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n        self.act = nn.ReLU(inplace=True)\n\n    def forward(self, x, skip):\n        x = self.up(x)\n        if x.shape[2:] != skip.shape[2:]:\n            skip = F.interpolate(skip, size=x.shape[2:], mode='bilinear', align_corners=False)\n        x = torch.cat([x, skip], dim=1)\n        x = self.act(self.conv1(x))\n        x = self.act(self.conv2(x))\n        return x\n\nclass DepthwiseConvTransformer(nn.Module):\n    def __init__(self, in_ch, out_ch, expansion=4):\n        super().__init__()\n        hidden = in_ch * expansion\n        self.proj1 = nn.Conv2d(in_ch, hidden, 1)\n        self.dw = nn.Conv2d(hidden, hidden, 3, padding=1, groups=hidden)\n        self.bn = nn.BatchNorm2d(hidden)\n        self.act = nn.GELU()\n        self.proj2 = nn.Conv2d(hidden, out_ch, 1)\n\n    def forward(self, x):\n        x = self.proj1(x)\n        x = self.dw(x)\n        x = self.bn(x)\n        x = self.act(x)\n        return self.proj2(x)\n\nclass ResBlock(nn.Module):\n    def __init__(self, ch):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(ch, ch, 3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(ch, ch, 3, padding=1),\n            nn.BatchNorm2d(ch),\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\n# Cell 3: Encoders\nclass EfficientNetB4Encoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = timm.create_model(\"efficientnet_b4\", pretrained=True, features_only=True)\n        self.out_ch = [24, 32, 56, 160, 448]\n\n    def forward(self, x):\n        return self.encoder(x)\n\nclass DenseNet121Encoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = timm.create_model(\"densenet121\", pretrained=True, features_only=True)\n\n    def forward(self, x):\n        return self.encoder(x)\n\n# Cell 4: Model Factory\nclass DualEncoderModel(nn.Module):\n    def __init__(self, variant):\n        super().__init__()\n        self.variant = variant\n\n        # --- Encoder 1 + optional Transformer ---\n        self.enc1 = EfficientNetB4Encoder()\n        bottleneck_ch = self.enc1.out_ch[-1]              # 448 for B4\n        self.use_dct = (variant not in ['a1'])  # include in full (a5)\n\n        self.trans = (\n            DepthwiseConvTransformer(bottleneck_ch, bottleneck_ch)\n            if self.use_dct else\n            nn.Identity()\n        )\n\n        # --- Decoder 1 (skip connections) ---\n        rev_ch = self.enc1.out_ch[::-1]   # [448,160,56,32,24]\n        skip_ch = rev_ch[1:]              # [160,56,32,24]\n        dec_chs  = [256, 128, 64, 32]\n        self.dec1 = nn.ModuleList([\n            SkipUpBlock(bottleneck_ch, skip_ch[0], dec_chs[0]),\n            SkipUpBlock(dec_chs[0], skip_ch[1], dec_chs[1]),\n            SkipUpBlock(dec_chs[1], skip_ch[2], dec_chs[2]),\n            SkipUpBlock(dec_chs[2], skip_ch[3], dec_chs[3]),\n            UpBlock(dec_chs[3], 16)\n        ])\n        self.head1 = nn.Conv2d(16, 1, kernel_size=1)\n\n        # --- Optional Encoder 2 branch ---\n        self.use_encoder2 = (variant not in ['a3'])  # include in full (a5)\n        if self.use_encoder2:\n            self.enc2 = DenseNet121Encoder()\n\n            # VSS vs ResBlock\n            self.use_vss = (variant not in ['a2'])  # include in full (a5)\n            if self.use_vss:\n                self.vss = nn.Sequential(\n                    nn.BatchNorm2d(1024),\n                    nn.Conv2d(1024, 1024, 1),\n                    nn.Conv2d(1024, 1024, 3, padding=1, groups=1024),\n                    nn.GELU(), nn.Dropout2d(0.1),\n                    nn.Conv2d(1024, 512, 1), nn.BatchNorm2d(512),\n                )\n                dec2_in_ch = 512\n            else:\n                self.vss = ResBlock(1024)\n                dec2_in_ch = 1024\n\n            # Decoder 2\n            self.dec2 = nn.ModuleList([\n                UpBlock(dec2_in_ch, 256),\n                UpBlock(256, 128),\n                UpBlock(128, 64),\n                UpBlock(64, 32),\n            ])\n            self.head2 = nn.Conv2d(32, 1, 1)\n\n        # --- Fusion or direct sum ---\n        self.fuse = nn.Conv2d(2, 1, 3, padding=1) if variant not in ['a4'] else None\n\n    def forward(self, x):\n        # Stage 1\n        f1 = self.enc1(x)\n        x1 = self.trans(f1[-1])                  # now always bottleneck_ch\n        for i, block in enumerate(self.dec1):\n            x1 = block(x1, f1[-2 - i]) if i < 4 else block(x1)\n        logit1 = self.head1(x1)\n\n        if not self.use_encoder2:\n            return logit1\n\n        # Stage 2\n        out1_prob = torch.sigmoid(logit1)\n        f2 = self.enc2(x * out1_prob)\n        x2 = self.vss(f2[-1])\n        for block in self.dec2:\n            x2 = block(x2)\n        logit2 = F.interpolate(self.head2(x2), size=logit1.shape[2:], mode='bilinear')\n\n        # Fuse or direct\n        if self.fuse:\n            return self.fuse(torch.cat([logit1, logit2], dim=1))\n        return logit1 + logit2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:43:28.371126Z","iopub.execute_input":"2025-07-18T05:43:28.371320Z","iopub.status.idle":"2025-07-18T05:43:28.406400Z","shell.execute_reply.started":"2025-07-18T05:43:28.371306Z","shell.execute_reply":"2025-07-18T05:43:28.405546Z"}},"outputs":[],"execution_count":2},{"id":"994aa2da","cell_type":"code","source":"# 3: Encoders\nclass EfficientNetB4Encoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = timm.create_model(\"efficientnet_b4\", pretrained=True, features_only=True)\n        self.out_ch = [24, 32, 56, 160, 448]\n\n    def forward(self, x):\n        return self.encoder(x)\n\nclass DenseNet121Encoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = timm.create_model(\"densenet121\", pretrained=True, features_only=True)\n\n    def forward(self, x):\n        return self.encoder(x)\n\n# Additional cells truncated for brevity...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:43:28.408327Z","iopub.execute_input":"2025-07-18T05:43:28.408590Z","iopub.status.idle":"2025-07-18T05:43:28.486094Z","shell.execute_reply.started":"2025-07-18T05:43:28.408544Z","shell.execute_reply":"2025-07-18T05:43:28.485283Z"}},"outputs":[],"execution_count":3},{"id":"004aaf1d-f049-4a92-915b-507842f77920","cell_type":"code","source":"# Cell 5: Dataset Loader\ndef get_dataset(name):\n    root = \"/kaggle/input\"\n    if name == \"kvasir\":\n        image_dir = f\"{root}/kvasirseg/Kvasir-SEG/Kvasir-SEG/images\"\n        mask_dir = f\"{root}/kvasirseg/Kvasir-SEG/Kvasir-SEG/masks\"\n    elif name == \"cvc\":\n        image_dir = f\"{root}/cvcclinicdb/PNG/Original\" \n        mask_dir = f\"{root}/cvcclinicdb/PNG/Ground Truth\" \n    elif name == \"bkai\":\n        image_dir = f\"{root}/bkai-igh-neopolyp/train/train\"\n        mask_dir = f\"{root}/bkai-igh-neopolyp/train_gt/train_gt\"\n    else:\n        raise ValueError(\"Unknown dataset\")\n\n    img_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir)])\n    mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir)])\n\n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor()\n    ])\n\n    class SegDataset(Dataset):\n        def __init__(self, imgs, masks):\n            self.imgs = imgs\n            self.masks = masks\n        def __len__(self): return len(self.imgs)\n        def __getitem__(self, i):\n            img = transform(Image.open(self.imgs[i]).convert(\"RGB\"))\n            mask = transform(Image.open(self.masks[i]).convert(\"L\"))\n            return img, (mask > 0).float()\n\n    X_train, X_val, y_train, y_val = train_test_split(img_paths, mask_paths, test_size=0.2, random_state=42)\n    return DataLoader(SegDataset(X_train, y_train), batch_size=8, shuffle=True), DataLoader(SegDataset(X_val, y_val), batch_size=8)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:43:28.486843Z","iopub.execute_input":"2025-07-18T05:43:28.487065Z","iopub.status.idle":"2025-07-18T05:43:28.507766Z","shell.execute_reply.started":"2025-07-18T05:43:28.487049Z","shell.execute_reply":"2025-07-18T05:43:28.506989Z"}},"outputs":[],"execution_count":4},{"id":"564be143-d531-4dfc-801d-c9f4d82aff3c","cell_type":"code","source":"\n# Cell 6: Loss, Metrics, Trainer\nclass DiceLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, y_pred, y_true):\n        y_pred = y_pred.contiguous()\n        y_true = y_true.contiguous()\n        intersection = (y_pred * y_true).sum(dim=(2, 3))\n        union = y_pred.sum(dim=(2, 3)) + y_true.sum(dim=(2, 3))\n        dice_score = (2. * intersection + 1) / (union + 1)\n        return 1 - dice_score.mean()\n\ndef evaluate(model, loader, device):\n    metrics = {\n        \"IoU\": BinaryJaccardIndex(threshold=0.5).to(device),\n        \"Dice\": BinaryF1Score(threshold=0.5).to(device),\n        \"Accuracy\": BinaryAccuracy(threshold=0.5).to(device),\n        \"Recall\": BinaryRecall(threshold=0.5).to(device),\n        \"Precision\": BinaryPrecision(threshold=0.5).to(device),\n        \"AUROC\": BinaryAUROC().to(device)\n    }\n    model.eval()\n    with torch.no_grad():\n        for metric in metrics.values(): metric.reset()\n        for images, masks in loader:\n            images, masks_f, masks_i = images.to(device), masks.to(device).float(), masks.to(device).int()\n            logits = model(images)\n            probs = torch.sigmoid(logits)\n            for name, metric in metrics.items():\n                metric.update(probs, masks_i)\n    return {k: float(m.compute()) for k, m in metrics.items()}\n\ndef train_one(model, train_loader, val_loader, device):\n    model.to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode='min', patience=3, factor=0.5)\n    bce, dice = nn.BCEWithLogitsLoss(), DiceLoss()\n    best_loss = float('inf')\n    for epoch in range(10):\n        model.train()\n        epoch_loss = 0\n        for images, masks in train_loader:\n            images, masks = images.to(device), masks.to(device)\n            optim.zero_grad()\n            logits = model(images)\n            probs = torch.sigmoid(logits)\n            loss = 0.5 * bce(logits, masks) + 0.5 * dice(probs, masks)\n            loss.backward()\n            optim.step()\n            epoch_loss += loss.item()\n        scheduler.step(epoch_loss / len(train_loader))\n    return evaluate(model, val_loader, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:43:28.508714Z","iopub.execute_input":"2025-07-18T05:43:28.508978Z","iopub.status.idle":"2025-07-18T05:43:28.528169Z","shell.execute_reply.started":"2025-07-18T05:43:28.508955Z","shell.execute_reply":"2025-07-18T05:43:28.527479Z"}},"outputs":[],"execution_count":5},{"id":"763652f5-f549-46f2-b755-3b69d5ba38ea","cell_type":"code","source":"variants = ['a5']\ndatasets = ['cvc', 'kvasir', 'bkai']\nresults = []\n\nfor variant in variants:\n    for dataset in datasets:\n        print(f\"\\nðŸš€ Running Variant: {variant.upper()} on Dataset: {dataset.upper()}\")\n        model = DualEncoderModel(variant)\n        train_loader, val_loader = get_dataset(dataset)\n        metrics = train_one(model, train_loader, val_loader, device)\n        result_row = {\"Variant\": variant, \"Dataset\": dataset, **metrics}\n        results.append(result_row)\n\n# Export Results\nresults_df = pd.DataFrame(results)\nresults_df.to_csv(\"ablation_results.csv\", index=False)\nprint(\"\\nâœ… Ablation Study Complete. Results saved to ablation_results.csv\")\nresults_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-18T05:43:28.529113Z","iopub.execute_input":"2025-07-18T05:43:28.529416Z","iopub.status.idle":"2025-07-18T06:03:54.958970Z","shell.execute_reply.started":"2025-07-18T05:43:28.529382Z","shell.execute_reply":"2025-07-18T06:03:54.958375Z"}},"outputs":[{"name":"stdout","text":"\nðŸš€ Running Variant: A5 on Dataset: CVC\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/77.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e23e254d00534907b1634d678c3d01a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/32.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc79371c8d8b4dfa909a16e3736f06f0"}},"metadata":{}},{"name":"stdout","text":"\nðŸš€ Running Variant: A5 on Dataset: KVASIR\n\nðŸš€ Running Variant: A5 on Dataset: BKAI\n\nâœ… Ablation Study Complete. Results saved to ablation_results.csv\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"  Variant Dataset       IoU      Dice  Accuracy    Recall  Precision     AUROC\n0      a5     cvc  0.782259  0.877829  0.978087  0.893318   0.862868  0.991297\n1      a5  kvasir  0.770625  0.870456  0.957073  0.849817   0.892121  0.982306\n2      a5    bkai  0.800258  0.889048  0.985748  0.884227   0.893922  0.993936","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Variant</th>\n      <th>Dataset</th>\n      <th>IoU</th>\n      <th>Dice</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>AUROC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a5</td>\n      <td>cvc</td>\n      <td>0.782259</td>\n      <td>0.877829</td>\n      <td>0.978087</td>\n      <td>0.893318</td>\n      <td>0.862868</td>\n      <td>0.991297</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a5</td>\n      <td>kvasir</td>\n      <td>0.770625</td>\n      <td>0.870456</td>\n      <td>0.957073</td>\n      <td>0.849817</td>\n      <td>0.892121</td>\n      <td>0.982306</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a5</td>\n      <td>bkai</td>\n      <td>0.800258</td>\n      <td>0.889048</td>\n      <td>0.985748</td>\n      <td>0.884227</td>\n      <td>0.893922</td>\n      <td>0.993936</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6}]}